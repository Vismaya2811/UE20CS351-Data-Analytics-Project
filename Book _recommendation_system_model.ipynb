{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQVqw3a-1FRK"
   },
   "source": [
    "**BOOK RECOMMENDATION SYSTEM - CONTENT BASED FILTERING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dInUZu4jO5Lg"
   },
   "source": [
    "EDA with Python Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     ------------------------------------ 293.3/293.3 kB 348.1 kB/s eta 0:00:00\n",
      "Collecting numpy!=1.24.0,>=1.17\n",
      "  Downloading numpy-1.24.2-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "     -------------------------------------- 14.8/14.8 MB 263.7 kB/s eta 0:00:00\n",
      "Collecting pandas>=0.25\n",
      "  Downloading pandas-2.0.0-cp311-cp311-win_amd64.whl (11.2 MB)\n",
      "     -------------------------------------- 11.2/11.2 MB 765.5 kB/s eta 0:00:00\n",
      "Collecting matplotlib!=3.6.1,>=3.1\n",
      "  Downloading matplotlib-3.7.1-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "     ---------------------------------------- 7.6/7.6 MB 743.1 kB/s eta 0:00:00\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp311-cp311-win_amd64.whl (162 kB)\n",
      "     -------------------------------------- 163.0/163.0 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 926.6 kB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp311-cp311-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 55.4/55.4 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
      "     -------------------------------------- 48.9/48.9 kB 822.7 kB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.5.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 838.2 kB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting python-dateutil>=2.7\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "     -------------------------------------- 502.3/502.3 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     -------------------------------------- 341.8/341.8 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, tzdata, six, pyparsing, pillow, packaging, numpy, kiwisolver, fonttools, cycler, python-dateutil, contourpy, pandas, matplotlib, seaborn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python311\\\\Scripts\\\\f2py.exe' -> 'C:\\\\Python311\\\\Scripts\\\\f2py.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "#hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpDREgbg0Tsx",
    "outputId": "e7f9d859-50f3-4e62-942f-2e4f96f97306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this dataframe, there are:\n",
      "6810 rows,\n",
      "12 columns\n",
      "\n",
      " The attributes/features are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "isbn13              int64\n",
       "isbn10             object\n",
       "title              object\n",
       "subtitle           object\n",
       "authors            object\n",
       "categories         object\n",
       "thumbnail          object\n",
       "description        object\n",
       "published_year    float64\n",
       "average_rating    float64\n",
       "num_pages         float64\n",
       "ratings_count     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('books.csv')\n",
    "print(f\"In this dataframe, there are:\\n{df.shape[0]} rows,\\n{df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n\",\"The attributes/features are:\")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yayo70dAPWPo"
   },
   "source": [
    "Rows: 6810 \n",
    "Attributes: 12 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uViRTgmLPzp9"
   },
   "source": [
    "**Analysis of Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BANaBXdkTI0C",
    "outputId": "cb2abea2-97cd-4ea7-bcbb-f8188c03036e"
   },
   "outputs": [],
   "source": [
    "# print(df.iloc[51])\n",
    "# df.drop(51,inplace=True)\n",
    "# print(df.iloc[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c_Wesea6sZh",
    "outputId": "b0d46046-db11-46ea-d0a9-7d3c597bb091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isbn13             0.00\n",
      "isbn10             0.00\n",
      "title              0.00\n",
      "subtitle          65.04\n",
      "authors            1.06\n",
      "categories         1.45\n",
      "thumbnail          4.83\n",
      "description        3.85\n",
      "published_year     0.09\n",
      "average_rating     0.63\n",
      "num_pages          0.63\n",
      "ratings_count      0.63\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "df.isnull().sum()\n",
    "print(round(percent_missing,2))\n",
    "# Therefore we can conclude that subtitle column has incomplete data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9YaJT8qQ3_N"
   },
   "source": [
    "**Dimensionality reduction**\n",
    "1. There are 65.02% of missing values in the feature 'subtitle', so we can conclude it is as incomplete data and drop the feature\n",
    "\n",
    "2. As the 'thumbnail','published_year', 'num_pages' attributes are irrelevent to our analysis, we have dropped them.\n",
    "\n",
    "3. Also, the features 'isbn10' and 'isbn13' serve the same purpose of unique identification of the book titles, we can consider the title for the identification and drop the 'isbn10' and 'isbn13' attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_1lZ87Q8qn0",
    "outputId": "5e591878-d028-4d36-d016-6ecfcfb7007d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'authors', 'categories', 'description', 'average_rating',\n",
       "       'ratings_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deletion of Unneccessary columns\n",
    "df.columns\n",
    "\n",
    "df.drop(columns=['subtitle','thumbnail','isbn10','isbn13','num_pages','published_year'],inplace=True)\n",
    "\n",
    "#After Deleting, the columns are\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT97e6en0xFO"
   },
   "source": [
    "**Handling missing data**\n",
    "We drop the null instances for the columns: 'authors', 'categories','description'\n",
    "\n",
    "Perform mean value imputation for:\n",
    "'average_rating','ratings_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tE4BNgKQ5IyS"
   },
   "outputs": [],
   "source": [
    "df['ratings_count'].fillna(df['ratings_count'].mean(), inplace=True)\n",
    "df['average_rating'].fillna(df['average_rating'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5mqGjwu0wPb",
    "outputId": "5aab95c1-4468-4979-de7e-2726b5c3ec89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title             0.0\n",
      "authors           0.0\n",
      "categories        0.0\n",
      "description       0.0\n",
      "average_rating    0.0\n",
      "ratings_count     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['authors', 'categories','description'])\n",
    "\n",
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "print(round(percent_missing,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijxvDRj9fKNL",
    "outputId": "6db6cb64-0646-4da4-82b2-71dc89ab082f"
   },
   "outputs": [],
   "source": [
    "# df.drop(df[df['num_pages'] == 0].index, inplace = True)\n",
    "# df['num_pages'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xAZL2eNeFby"
   },
   "source": [
    "**MODEL BUILDING-->**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1HQQsh9eE-x",
    "outputId": "f653c56c-38b3-4413-c460-7164853fa995"
   },
   "outputs": [],
   "source": [
    "##Convert columns values in lowercase\n",
    "df['description']=df['description'].str.lower()\n",
    "df['title']=df['title'].str.lower()\n",
    "df['authors']=df['authors'].str.lower()\n",
    "df['categories']=df['categories'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe2PhPw8mLH0"
   },
   "source": [
    "Combine book and rating using .merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JtWRClMmfKeo"
   },
   "outputs": [],
   "source": [
    "# Index dataset using Title\n",
    "#df = df.set_index(['isbn13']) #Indexed dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "6r3qDUMKm1Qy",
    "outputId": "b58b5e51-058f-46a7-96bc-04481a7e567a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gilead</td>\n",
       "      <td>marilynne robinson</td>\n",
       "      <td>fiction</td>\n",
       "      <td>a novel that readers and critics have been eag...</td>\n",
       "      <td>3.85</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spider's web</td>\n",
       "      <td>charles osborne;agatha christie</td>\n",
       "      <td>detective and mystery stories</td>\n",
       "      <td>a new 'christie for christmas' -- a full-lengt...</td>\n",
       "      <td>3.83</td>\n",
       "      <td>5164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the one tree</td>\n",
       "      <td>stephen r. donaldson</td>\n",
       "      <td>american fiction</td>\n",
       "      <td>volume two of stephen donaldson's acclaimed se...</td>\n",
       "      <td>3.97</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rage of angels</td>\n",
       "      <td>sidney sheldon</td>\n",
       "      <td>fiction</td>\n",
       "      <td>a memorable, mesmerizing heroine jennifer -- b...</td>\n",
       "      <td>3.93</td>\n",
       "      <td>29532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the four loves</td>\n",
       "      <td>clive staples lewis</td>\n",
       "      <td>christian life</td>\n",
       "      <td>lewis' work on the nature of love divides love...</td>\n",
       "      <td>4.15</td>\n",
       "      <td>33684.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                          authors  \\\n",
       "0          gilead               marilynne robinson   \n",
       "1    spider's web  charles osborne;agatha christie   \n",
       "2    the one tree             stephen r. donaldson   \n",
       "3  rage of angels                   sidney sheldon   \n",
       "4  the four loves              clive staples lewis   \n",
       "\n",
       "                      categories  \\\n",
       "0                        fiction   \n",
       "1  detective and mystery stories   \n",
       "2               american fiction   \n",
       "3                        fiction   \n",
       "4                 christian life   \n",
       "\n",
       "                                         description  average_rating  \\\n",
       "0  a novel that readers and critics have been eag...            3.85   \n",
       "1  a new 'christie for christmas' -- a full-lengt...            3.83   \n",
       "2  volume two of stephen donaldson's acclaimed se...            3.97   \n",
       "3  a memorable, mesmerizing heroine jennifer -- b...            3.93   \n",
       "4  lewis' work on the nature of love divides love...            4.15   \n",
       "\n",
       "   ratings_count  \n",
       "0          361.0  \n",
       "1         5164.0  \n",
       "2          172.0  \n",
       "3        29532.0  \n",
       "4        33684.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiM-xJvXsnHH"
   },
   "source": [
    "**DATA WRANGLING:**\n",
    "Also called Data munging, it is the process of transforming and mapping data from one \"raw\" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PY8keMK39fT6"
   },
   "source": [
    "Order of execution: Convert to lowercase, remove stop words, then lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9FLV1IDW0Kl",
    "outputId": "5155221a-3900-4adb-e3cf-0a13e89d7686"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vismaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vismaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vismaya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Vismaya\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "#from collections import Counter \n",
    "\n",
    "#from nltk.corpus import wordnet # To get words in dictionary with their parts of speech\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jXWDfY8qs9py"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hxpDYcUmiRbL"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "#REMOVE PUNCTUATIONS\n",
    "def rem_punctuations(text):\n",
    "    for punctuation in string.punctuation: #string.punctuation gives all set of punctuations\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "df['description'] = df['description'].apply(rem_punctuations)\n",
    "\n",
    "# df['authors']=df['authors'].apply(rem_punctuations)\n",
    "# df['categories']=df['categories'].apply(rem_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "h5yy-ivZ9uO-"
   },
   "outputs": [],
   "source": [
    "# REMOVE NON ASCII CHARACTERS\n",
    "def remove_non_ascii(string):\n",
    "    return \"\".join(c for c in string if ord(c) < 128)\n",
    "\n",
    "df['description'] = df['description'].apply(remove_non_ascii)\n",
    "# df['title']=df['title'].apply(remove_non_ascii)\n",
    "# df['authors']=df['authors'].apply(remove_non_ascii)\n",
    "# df['categories']=df['categories'].apply(remove_non_ascii)\n",
    "\n",
    "# REMOVE HTML CODES\n",
    "def rem_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "df['description'] = df['description'].apply(rem_html)\n",
    "# df['authors']=df['authors'].apply(rem_html)\n",
    "# df['categories']=df['categories'].apply(rem_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZyMr6I1riwAZ"
   },
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def rem_stopwords(text):\n",
    "    return \" \".join(word for word in str(text).split() if word not in set(stopwords.words('english')))\n",
    "\n",
    "df['description'] = df['description'].apply(rem_stopwords)\n",
    "# df['categories']=df['categories'].apply(rem_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWXapaWbo2g3"
   },
   "source": [
    "**Lemmatization of Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "laXqZtbbcm7d"
   },
   "outputs": [],
   "source": [
    "wln = WordNetLemmatizer()\n",
    "\n",
    "def lem_words(text):\n",
    "    return \" \".join(wln.lemmatize(word) for word in text.split())\n",
    "\n",
    "df['description']=df['description'].apply(lem_words)\n",
    "#df['authors']=df['authors'].apply(lem_words)\n",
    "#df['categories']=df['categories'].apply(lem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBoCv8ldpTVb"
   },
   "source": [
    "**Remove Extra Spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MiELhNUDtYzy"
   },
   "outputs": [],
   "source": [
    "df['description']=df['description'].str.strip()\n",
    "# df['authors']=df['authors'].str.strip()\n",
    "# df['categories']=df['categories'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XorMaYHSfVYl"
   },
   "outputs": [],
   "source": [
    "#Joining Authors name with space\n",
    "# def join_space(text):\n",
    "#     return text.replace(\" \",\"\")\n",
    "\n",
    "# df['authors']=df['authors'].apply(join_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQV77wsvra4w",
    "outputId": "24ac5f57-d239-4def-ce0c-39adaa2baeda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3.850915\n",
       "1       3.830080\n",
       "2       3.969109\n",
       "3       3.930000\n",
       "4       4.149973\n",
       "          ...   \n",
       "6803    3.733730\n",
       "6804    3.820290\n",
       "6805    4.488116\n",
       "6808    3.931657\n",
       "6809    3.767245\n",
       "Name: weighted_rating, Length: 6446, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WEighted average\n",
    "v=df['ratings_count'] #11800, 4500, 4466, etc.\n",
    "R=df['average_rating'] # 7.2, 6.9, 6.3, 7.6, etc.\n",
    "C=df['average_rating'].mean() # 6.092171559442011\n",
    "m=df['average_rating'].quantile(0.70) # 581.0\n",
    "\n",
    "df['weighted_rating']=((R*v)+ (C*m))/(v+m)\n",
    "\n",
    "df['weighted_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "xIkEUpiQj7W6",
    "outputId": "2931e8fb-d38c-4d34-bba6-e60c4c0a1938"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>weighted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gilead</td>\n",
       "      <td>marilynne robinson</td>\n",
       "      <td>fiction</td>\n",
       "      <td>novel reader critic eagerly anticipating decad...</td>\n",
       "      <td>3.85</td>\n",
       "      <td>361.0</td>\n",
       "      <td>3.850915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spider's web</td>\n",
       "      <td>charles osborne;agatha christie</td>\n",
       "      <td>detective and mystery stories</td>\n",
       "      <td>new christie christmas fulllength novel adapte...</td>\n",
       "      <td>3.83</td>\n",
       "      <td>5164.0</td>\n",
       "      <td>3.830080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the one tree</td>\n",
       "      <td>stephen r. donaldson</td>\n",
       "      <td>american fiction</td>\n",
       "      <td>volume two stephen donaldsons acclaimed second...</td>\n",
       "      <td>3.97</td>\n",
       "      <td>172.0</td>\n",
       "      <td>3.969109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rage of angels</td>\n",
       "      <td>sidney sheldon</td>\n",
       "      <td>fiction</td>\n",
       "      <td>memorable mesmerizing heroine jennifer brillia...</td>\n",
       "      <td>3.93</td>\n",
       "      <td>29532.0</td>\n",
       "      <td>3.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the four loves</td>\n",
       "      <td>clive staples lewis</td>\n",
       "      <td>christian life</td>\n",
       "      <td>lewis work nature love divide love four catego...</td>\n",
       "      <td>4.15</td>\n",
       "      <td>33684.0</td>\n",
       "      <td>4.149973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                          authors  \\\n",
       "0          gilead               marilynne robinson   \n",
       "1    spider's web  charles osborne;agatha christie   \n",
       "2    the one tree             stephen r. donaldson   \n",
       "3  rage of angels                   sidney sheldon   \n",
       "4  the four loves              clive staples lewis   \n",
       "\n",
       "                      categories  \\\n",
       "0                        fiction   \n",
       "1  detective and mystery stories   \n",
       "2               american fiction   \n",
       "3                        fiction   \n",
       "4                 christian life   \n",
       "\n",
       "                                         description  average_rating  \\\n",
       "0  novel reader critic eagerly anticipating decad...            3.85   \n",
       "1  new christie christmas fulllength novel adapte...            3.83   \n",
       "2  volume two stephen donaldsons acclaimed second...            3.97   \n",
       "3  memorable mesmerizing heroine jennifer brillia...            3.93   \n",
       "4  lewis work nature love divide love four catego...            4.15   \n",
       "\n",
       "   ratings_count  weighted_rating  \n",
       "0          361.0         3.850915  \n",
       "1         5164.0         3.830080  \n",
       "2          172.0         3.969109  \n",
       "3        29532.0         3.930000  \n",
       "4        33684.0         4.149973  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePtmg4szkRZa",
    "outputId": "c2734a60-6a33-4d08-bd9a-483166eae40f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novel reader critic eagerly anticipating decade gilead astonishingly imagined story remarkable life john ames preacher son preacher grandson maternal paternal preacher 1956 gilead iowa towards end reverend amess life absorbed recording family story legacy young son never see grow haunted grandfather presence john tell rift grandfather father elder angry visionary fought abolitionist cause son ardent pacifist troubled prodigal namesake jack john ames boughton best friend lost son return gilead searching forgiveness redemption told john amess joyous rambling voice find beauty humour truth smallest life detail gilead song celebration acceptance best worst world offer heart tale sacred bond father son pitchperfect style story set dazzle critic reader alike\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "def tostr(text):\n",
    "    return ''.join(text)\n",
    "\n",
    "df['description']=df['description'].apply(tostr)\n",
    "print(df['description'][0])\n",
    "type(df['description'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FavuRlGThr22"
   },
   "outputs": [],
   "source": [
    "df['keyword']=df['description']+\" \"+df['authors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "yM7wwkgxtl00"
   },
   "outputs": [],
   "source": [
    "#fetch category inside function- working recommend function\n",
    "\n",
    "def recommend(title):\n",
    "    title= title.lower()\n",
    "    \n",
    "    #Fetch the category of our title\n",
    "    titlerow = df.loc[df['title']== title].iloc[0]\n",
    "    category=titlerow['categories']\n",
    "\n",
    "    # MATCH THE CATEGORY WITH THE COLUMN \"CATEGORIES\" OF THE DATASET\n",
    "    data = df.loc[df['categories'] == category].copy()\n",
    "\n",
    "    if len(data)<=10: ##As our dataset is unbalanced, if the matching category contains less than 10 book titles\n",
    "      data=df.copy()          #,then we ommit the category filtering\n",
    "\n",
    "\n",
    "    # RESET INDEX\n",
    "    data.reset_index(level = 0, inplace = True, drop=True) \n",
    "    \n",
    "    # INDEX TO A PANDAS SERIES\n",
    "    indices = pd.Series(data.index, index = data['title'])\n",
    "    \n",
    "    # CONVERT THE BOOK TITLE INTO VECTORS AND USE BIGRAM\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(2, 2), min_df = 1, stop_words='english',sublinear_tf=True)\n",
    "    \n",
    "    # tfidf_matrix = tf.fit_transform(data['title'])\n",
    "    #sublinear_tfbool, default=False\n",
    "    #Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf)\n",
    "    \n",
    "    tfidf_matrix = tf.fit_transform(data['keyword'])\n",
    "    \n",
    "    # CALCULATE THE SIMILARITY MEASURE\n",
    "    similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    # GET THE INDEX OF ORIGINAL TITLE\n",
    "    title_index = indices[title].tolist()\n",
    "    print(\"title_index\",title_index)\n",
    "    if not(type(title_index) is int): \n",
    "        \n",
    "        title_index=title_index[0]    #if more than one matching index exists, take the 1st one\n",
    "        inds=indices[title].tolist()\n",
    "        for i in inds:   #to drop other rows with the same title\n",
    "          if i!=title_index:\n",
    "            print('index dropped:',i)\n",
    "            data.drop(i,inplace=True)\n",
    "    \n",
    "    # PAIRWISE SIMILARITY SCORES\n",
    "    similarity = list(enumerate(similarity[title_index]))\n",
    "    \n",
    "    # SORT THE BOOKS\n",
    "    similarity = sorted(similarity, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # GET TOP 10 MOST SIMILAR BOOKS\n",
    "    similarity  = similarity [1:11]\n",
    "    print(\"similarity:\",similarity,\"\\n\")\n",
    "    book_indices = [i[0] for i in similarity]\n",
    "\n",
    "    #Weighted Rating method\n",
    "    top10_rated = data['weighted_rating'].iloc[book_indices]\n",
    "    wsort = top10_rated.sort_values(ascending = False)\n",
    "    wsort_top5 = wsort[:6]\n",
    "    wsort_top5.to_frame()\n",
    "\n",
    "    # INDICES OF TOP 5\n",
    "    wsort_indices = wsort_top5.index\n",
    "    #print(wsort_indices)\n",
    "\n",
    "    # TOP 5 RECOMMENDATION\n",
    "    rec = data[['title']].iloc[wsort_indices]\n",
    "    \n",
    "    # PRINT THE BOOKS TITLE\n",
    "    print(\"\\n\",\"The recommendations are:\")\n",
    "    print(rec['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkKUI-kXvAy_",
    "outputId": "44c7fa5d-b1ef-4ac5-8a79-b832cf71f4d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_index [1110, 2382]\n",
      "index dropped: 2382\n",
      "similarity: [(2387, 0.08564157267058235), (2389, 0.0778467844233684), (2382, 0.07584790701103701), (368, 0.07337464099435693), (2390, 0.06578136556475976), (606, 0.0549890514894677), (2386, 0.050347001119664156), (2383, 0.05029005291203832), (519, 0.04764768220636827), (3, 0.04191084589035031)] \n",
      "\n",
      "\n",
      " The recommendations are:\n",
      "519     absent in the spring and other novels\n",
      "2385                  the body in the library\n",
      "2392                                  prophet\n",
      "2384                   murder at the vicarage\n",
      "2389                        death on the nile\n",
      "2388                    a murder is announced\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommend(\"Murder on the Orient Express\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnXnsKadFNQ6",
    "outputId": "e9fae30e-aa2c-49d8-9ec3-3a7f2a80a254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_index 231\n",
      "similarity: [(243, 0.8448622967175232), (218, 0.08208474106560615), (193, 0.0491516362182596), (202, 0.04817069815050505), (219, 0.04169553075617062), (106, 0.04113347348944385), (291, 0.04064722627952388), (239, 0.027965698946575898), (390, 0.02265937358058459), (229, 0.012557868183357366)] \n",
      "\n",
      "\n",
      " The recommendations are:\n",
      "243                          the harry potter collection\n",
      "239      harry potter and the half-blood prince (book 6)\n",
      "229    harry potter and the prisoner of azkaban (book 3)\n",
      "390                  harry potter and the goblet of fire\n",
      "202    harry potter and the order of the phoenix (boo...\n",
      "219       harry potter and the sorcerer's stone (book 1)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommend(\"harry potter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bzjUVEFRvwF",
    "outputId": "361c4940-5e77-46ab-be51-b9ec53ad3d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_index 3266\n",
      "similarity: [(3269, 0.15777878240489793), (2325, 0.05440497467778775), (2278, 0.04713636249146537), (3535, 0.046677060244957866), (5974, 0.04355468135128589), (5975, 0.04355468135128589), (5558, 0.0422856323481561), (1231, 0.03939145669247465), (4325, 0.038132906759446014), (4909, 0.038132906759446014)] \n",
      "\n",
      "\n",
      " The recommendations are:\n",
      "3269    the illustrated a brief history of time\n",
      "3535    the illustrated a brief history of time\n",
      "2278              the annotated christmas carol\n",
      "1231          contemporary political philosophy\n",
      "4909           twelfth night, or, what you will\n",
      "2325                    the future of spacetime\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommend('a brief History of time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijSlUVYQ2Rz_",
    "outputId": "f71d61e9-ada1-4475-d38e-e21de790707c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_index 26\n",
      "similarity: [(0, 0.012193128473190555), (4, 0.006878282708655834), (1, 0.0), (2, 0.0), (3, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0)] \n",
      "\n",
      "\n",
      " The recommendations are:\n",
      "0       declarations of independence\n",
      "1                       the crusader\n",
      "5                seeing like a state\n",
      "2                 homegrown democrat\n",
      "9    the collapse of the common good\n",
      "4     the intellectuals and the flag\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "#recommend(\"death note\")\n",
    "recommend(\"Mahatma Gandhi and His Myths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Mch8G5-mnXI",
    "outputId": "d105e8df-6e86-404c-dcc0-2017eb8b2661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_index [30, 32]\n",
      "index dropped: 32\n",
      "similarity: [(32, 0.15548867862586885), (16, 0.01805570349835141), (33, 0.01494501132498283), (26, 0.014021036860196262), (29, 0.010683190192862096), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0)] \n",
      "\n",
      "\n",
      " The recommendations are:\n",
      "16                                 hackers & painters\n",
      "29                                   programming ruby\n",
      "2                                                java\n",
      "4                  robin williams web design workshop\n",
      "0     incident response & computer forensics, 2nd ed.\n",
      "26                          php and mysql for dummies\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommend(\"agile web development with rails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-QDAJu0vE07D",
    "outputId": "e3fabcd3-f44e-4664-e8be-da27e489c4c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_index [986, 2265]\n",
      "index dropped: 2265\n",
      "similarity: [(2265, 0.23272001551643492), (2315, 0.04941560732574825), (418, 0.03283304485458853), (1341, 0.024515584006773512), (288, 0.022477165089281284), (2316, 0.019433503015860887), (285, 0.01877549695808719), (1346, 0.017049767167448472), (1917, 0.016906604689856046), (1769, 0.016566195718722962)] \n",
      "\n",
      "\n",
      " The recommendations are:\n",
      "1341    les miserables a new unabridged translation\n",
      "288                                  les miserables\n",
      "2267                                        company\n",
      "418                            flowers for algernon\n",
      "1769                             the tombs of atuan\n",
      "1346                    the hunchback of notre-dame\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommend(\"the da vinci code\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
